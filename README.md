# 100 Codings Days
Building BNEAY simple Chatbot.
This project is way for me to talk about what i'm passionate about (machine learning), Learn new things related to that field, and at the same time apply what im learning currently in software engineering to build a simple chatbot ad deploy it on a website for people to test.

Stay tuned for the whole duration of this projects to travel and discover new stuff with me this whole journey.

## Day 1: (1st April 2023)
I took a peak into Natural Language Processing (NLP), That I still will be learning it's theoritical backround in the upcoming days before moving to applying with its implementation in Python. and I have identified some main steps to achieve it, the first one is Tokenization:
### Tokenization:
Tokenization is the process of breaking down a text into individual words or phrases, known as tokens. This is an essential step in many natural language processing (NLP) applications, as it allows the system to work with discrete units of text rather than attempting to analyze the entire text as a whole.

There are several methods for tokenization, but the most common approach is to split the text at the spaces between words. However, this simple approach can be problematic for languages that don't use spaces between words, such as Chinese and Japanese.

To handle these cases, more advanced tokenization techniques may be used, such as using machine learning algorithms to identify word boundaries based on patterns in the text. This approach can be more accurate but also more complex to implement.

Once the text has been tokenized, it can be used as input to other NLP processes such as part of speech tagging, parsing, and sentiment analysis. Tokenization is therefore a critical step in many NLP applications and is an important concept to understand for anyone working with natural language data. All these Notions that has been cited i this paragraph will be detailed later on, before moving on to the application of all concepts. Stay Tuuuuuned !! :)

